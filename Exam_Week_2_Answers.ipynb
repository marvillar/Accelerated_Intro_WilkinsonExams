{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "\n",
    "</pre>\n",
    "\n",
    "## Start your mySQL Server from a terminal \n",
    "(if it isn't already running)\n",
    "\n",
    "<code>sudo docker start course-mysql</code>\n",
    "<pre>\n",
    "\n",
    "</pre>\n",
    "Don't forget that, if you use sqlMagic, you need to execute the connection lines in your Notebook!\n",
    "\n",
    "<pre>\n",
    "%load_ext sql\n",
    "%config SqlMagic.autocommit=False\n",
    "%sql mysql+pymysql://root:root@127.0.0.1:3306/mysql\n",
    "</pre>\n",
    "\n",
    "## Create a new Python3 Jupyter Notebook in your Exam Answers folder\n",
    "\n",
    "Commit and push this Notebook to GitHub when you are finished.\n",
    "\n",
    "You must submit your answers to GitHub by 1800h Sept 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config SqlMagic.autocommit=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql mysql+pymysql://root:root@127.0.0.1:3306/mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to prepare the conexion between Computer(VM) -> Docker MySQL -> Jupyter notebook\n",
    "#print (\"loading conexions and some SqlMagic...\\n\")\n",
    "#%load_ext sql\n",
    "#%reload_ext sql #if we want to reconect\n",
    "#%config SqlMagic.autocommit=False # load SqlMagic for exercises 4 and 5\n",
    "#%sql mysql+pymysql://root:root@127.0.0.1:3306/mysql #conect with root@mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Data Files\n",
    "Germplasm.tsv and LocusGene.tsv contain the datasets we need for the exam.\n",
    "\n",
    "Our objective is to create a database to contain the data in these files, insert the data into the database, then query the database in a variety of ways.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 1:  Controls\n",
    "\n",
    "Write a Python script that proves that the lines of data in Germplasm.tsv, and LocusGene are in the same sequence, based on the AGI Locus Code (ATxGxxxxxx).  (hint: This will help you decide how to load the data into the database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN BOTH FILES (\"Germplasm.tsv\" and \"LocusGene.tsv\"). \n",
    "\n",
    "file1 = open(\"Germplasm.tsv\", \"r\") ##Open Germplasm.tsv and call it: file1. \"r\" = means read permissions.\n",
    "print(file1.read()) #check the file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open(\"LocusGene.tsv\", \"r\") ##Open LocusGene.tsv and call it: file1. \"r\" = means read permissions.\n",
    "print(file2.read()) #check the file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created both objects (file1 and file2) in case in the future I need to use the code again but with different files. I would have to change the match word and aldo the name of both files to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code (Conditional loop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file1 = open(\"Germplasm.tsv\", \"r\") #Don't forget to open both files\n",
    "#file2 = open(\"LocusGene.tsv\", \"r\") #Don't forget to open both files\n",
    "\n",
    "file1.seek(0) #(0) In file1 re-start the pointer to 0 every time that we want to run the code.\n",
    "#file1.seek(0) #(0) Not need. We will do it each iteration at the beginning of the second loop \n",
    "\n",
    "list1 = [] #(1) Empty list1, we will need it to fill with the data that we will generate in tota_matches_file1\n",
    "list2 = [] #(1) Empty list1, we will need it to fill with the data that we will generate in tota_matches_file1\n",
    "\n",
    "a = 0 in range(1, 100) #(1) Control number, to calculate the iterations number (check step )\n",
    "\n",
    "\n",
    "for search in file1.readlines(): #(2) for each \"search\" in the first file.\n",
    "    match_in1 = re.search( r'(AT\\w+)(\\t)', search, re.M|re.I) #(3) create \"match_in1\" with the string that we want to search\n",
    "    if match_in1: #(4) If this string exists do next (5-6) and create the next loop (8)\n",
    "        total1 = match_in1.group(1) #(5) create an object with the search results in group 1 (I want to exclude the tab)\n",
    "        list1.append(total1) #(6) Fill the list1 with the results obtained before\n",
    "        file2.seek(0) #(7) re-start the pointer. We need to search in the whole file every time!\n",
    "        for search2 in file2.readlines(): #(8) Do the same with the file2 (steps 3 to 6)\n",
    "            match_in2 = re.search( r'(AT\\w+)(\\t)', search2, re.M|re.I) #(9) = (3) re.M = Multiline; re.I= case insensitive\n",
    "            a = a + 1 #(10) Check point, Iterative number: we will check if the program ran correctly.\n",
    "            if match_in2: #(11) If it's a match then:\n",
    "                total2 = match_in2.group(1) #(12) create an object with the search withing group 2\n",
    "                list2.append(total2) #(14) Fills the list2 with the info at total2\n",
    "                if (total1) == (total2): #(13) Finally, if both results matches \n",
    "                    print ('Iteration', str(a), 'found', total2, 'match in both documents.') #Iteration = iteration number.\n",
    "    else:\n",
    "        print('Not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Note: the first result is \"Not found\", this is because the headers doesn't follow the rule that we have create for the matches ((AT\\w+)(\\t)). \n",
    "2. Iteration number it is absolutly not need but it helps me to better understand the loop process. In the same way, is usefull to appreciate the computational effort.\n",
    "3. Check point: if we are doing right the number of iteratins should be less than the possible number of combinations in the table. \n",
    "4. An easier way to solve the problem could be using matrices and the column \"locus\" but I don't know how to use them.\n",
    "5. Also, it could be solve with %sql and join the common parts and checking the result (if the number of cases are both equals we proove that the lines are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2:  Design and create the database.  \n",
    "* It should have two tables - one for each of the two data files.\n",
    "* The two tables should be linked in a 1:1 relationship\n",
    "* you may use either sqlMagic or pymysql to build the database\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database desing: Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The Locus will be the PRIMARY KEY of both tables. They have to be UNIQUE.\n",
    "    1.A In case that you have a repeticion of any Locus you can add (.1 to .n). BUT! In this database is better to don't do it (It will be better to create another database with auto_icremented value as a primary key)\n",
    "2. Null is not allowed.\n",
    "3. Use \"unknown\" if you don't know the information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config SqlMagic.autocommit=False # re-load SqlMagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql drop database Exam2; #sql=specific comand to MySQL, drop = erase the table. \n",
    "%sql create database Exam2; # create database for create a database followed by the name (Exam2)\n",
    "%sql show databases; #show the databases. Check if we are doing good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tables inside Exam2 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql use Exam2; \n",
    "%sql show tables; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Germplasm table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%sql drop table Germplasm;\n",
    "%sql CREATE TABLE Germplasm(Locus_germ VARCHAR(20) NOT NULL PRIMARY KEY, germplasm VARCHAR(60) NOT NULL, phenotype VARCHAR(2000) NOT NULL, pubmed VARCHAR(70) NOT NULL);\n",
    "%sql DESCRIBE Germplasm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) LocusGene table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%sql drop table LocusGene;\n",
    "%sql CREATE TABLE LocusGene(Locus_gene VARCHAR(50) NOT NULL PRIMARY KEY, Gene VARCHAR(50) NOT NULL, ProteinLength VARCHAR(50) NOT NULL);\n",
    "%sql DESCRIBE LocusGene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql show tables; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can check with show databases, the tables have been created correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM Germplasm INNER JOIN LocusGene ON Locus_germ = Locus_gene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choosed INNER JOIN because I want to join both tables with all the data in common (Locus) both are primary keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Fill the database\n",
    "Using pymysql, create a Python script that reads the data from these files, and fills the database.  There are a variety of strategies to accomplish this.  I will give all strategies equal credit - do whichever one you are most confident with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and conexions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import csv\n",
    "#csv.list_dialects() #extra info for specific formats\n",
    "\n",
    "# Connect to the database.\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Germplasm table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Connect to the database.\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor: \n",
    "        with open('Germplasm.tsv') as csvfile:\n",
    "            GermReader = csv.DictReader(csvfile, delimiter='\\t', quotechar='\"')                          \n",
    "            for row in GermReader:\n",
    "                normaldict = dict(row) \n",
    "                #print(row) #Check point\n",
    "                sql = \"\"\"INSERT INTO Germplasm(Locus_germ, germplasm, phenotype, pubmed) values\n",
    "                ('{}', '{}', '{}', '{}')\"\"\".format(row[\"Locus\"], row[\"germplasm\"], row[\"phenotype\"], row[\"pubmed\"])\n",
    "                cursor.execute(sql)\n",
    "    connection.commit() # NOTE THAT I AM FORCING THE WRITE TO THE DATABASE HERE\n",
    "\n",
    "finally:\n",
    "    #print(\"\")\n",
    "    connection.close() # if I close before I commit, the inserts are lost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I filled the table Germplasm with the data from the file \"Germplasm.tsv\".\n",
    "\n",
    "First of all I prepared the conection for the database. Then I used try with for teast my lines, the table will be loaded if everithing is OK (finally print and close the connection.\n",
    "\n",
    "I created a reader called Germreader. I specified that our file it is tab delimited, also I put quotechar (just in case) and I specified the name of the headers in order. After the creation of this object (GermReader). I created a loop.\n",
    "\n",
    "This loops insert into our empty table (Germplasm) with the headers specified in (), and asings the character values '{}' (referst to the VARCHAR that I created before in exercise 2) that found in the row (row[\"Locus\"], row[\"germplasm\"], row[\"phenotype\"], row[\"pubmed\"]). Format help us to introduce the correct type of format.\n",
    "\n",
    "If we open the table we will see that its now the table is filled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM Germplasm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locusgene table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to do the same for the empty Locusgene table that I have created before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql drop table LocusGene;\n",
    "%sql CREATE TABLE LocusGene(Locus_gene VARCHAR(50) NOT NULL PRIMARY KEY, Gene VARCHAR(50) NOT NULL, ProteinLength VARCHAR(50) NOT NULL);\n",
    "#I use the code again, just to code faster.\n",
    "\n",
    "#Connect to the database.\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor: \n",
    "        with open('LocusGene.tsv') as csvfile:\n",
    "            LocusReader = csv.DictReader(csvfile, delimiter='\\t', quotechar='\"')                          \n",
    "            for row in LocusReader:\n",
    "                normaldict = dict(row)\n",
    "                #print(row)\n",
    "                sql = \"\"\"INSERT INTO LocusGene(Locus_gene, Gene, ProteinLength) values\n",
    "                ('{}', '{}', '{}')\"\"\".format(row[\"Locus\"], row[\"Gene\"], row[\"ProteinLength\"])\n",
    "                cursor.execute(sql)\n",
    "    connection.commit() # NOTE THAT I AM FORCING THE WRITE TO THE DATABASE HERE\n",
    "\n",
    "finally:\n",
    "    #print(\"\")\n",
    "    connection.close() # if I close before I commit, the inserts are lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Germ = csv.DictReader(csvfile, delimiter \\t, fieldnames=(\"Locus\", \"germplasm\", \"phenotype\",\"phenotype\"))\n",
    "\n",
    "%sql SELECT * FROM LocusGene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Create reports, written to a file\n",
    "\n",
    "1. Create a report that shows the full, joined, content of the two database tables (including a header line)\n",
    "\n",
    "2. Create a joined report that only includes the Genes SKOR and MAA3\n",
    "\n",
    "3. Create a report that counts the number of entries for each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx)\n",
    "\n",
    "4. Create a report that shows the average protein length for the genes on each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx)\n",
    "\n",
    "When creating reports 2 and 3, remember the \"Don't Repeat Yourself\" rule! \n",
    "\n",
    "All reports should be written to **the same file**.  You may name the file anything you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert to a normal Dictionary, do the following\n",
    "        #normaldict = dict(row)  # convert to normal dictionary\n",
    "        #print(list(normaldict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and conect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "\n",
    "#Connect to the database.\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Report file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Report. Full, joined, content of the two databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "join = %sql SELECT locus_germ, germplasm, phenotype, pubmed FROM Germplasm INNER JOIN LocusGene ON Locus_germ = Locus_gene\n",
    "report1 = (list(join))\n",
    "print(report1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Report. Genes SKOR and MAA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "report2a = %sql SELECT * FROM Germplasm INNER JOIN LocusGene ON Locus_germ = Locus_gene WHERE gene LIKE 'SKOR' OR gene LIKE 'MAA3'\n",
    "\n",
    "print(report2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Entries of Chr 1 and Chr 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report3 = %sql SELECT COUNT(*) AS \"Number of Matches\" FROM Germplasm, WHERE Locus_gene LIKE 'AT1' + 'G*' + '\\t' OR gene LIKE  'AT1' + 'G*' + '\\t'\n",
    "print(report3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now from the tsv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "report2 = ()\n",
    "LocusGene = open(\"Germplasm.tsv\", \"r\")\n",
    "\n",
    "\n",
    "LocusGene.seek(0)\n",
    "\n",
    "with open('Germplasm.tsv') as csvfile:\n",
    "    locus_Reader = csv.DictReader(csvfile, delimiter=\"\\t\", quotechar='\"')\n",
    "    LocusGene.seek(0)\n",
    "    for item in locus_Reader:\n",
    "        matchObj = re.search( r'((AT1)\\w+|(AT5)\\w+)', item[\"Locus\"], re.M|re.I)\n",
    "        if matchObj:\n",
    "            report2 = print(\"Entrie no.\", (a + 1), \": {} \".format(item[\"Locus\"]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Average protein lenght for the genes AT1 and AT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "rep = []\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('LocusGene.tsv') as csvfile:\n",
    "    protein_Reader = list(csv.DictReader(csvfile, delimiter=\"\\t\"))\n",
    "    for item in protein_Reader:\n",
    "        matchObj = re.search( r'((AT1)\\w+|(AT5)\\w+)', item[\"Locus\"], re.M|re.I)\n",
    "        if matchObj:\n",
    "            rep = print(\"{}\".format(item[\"ProteinLength\"]))\n",
    "      # NOTE!  using \"list\" here is memory-dangerous!\n",
    "    #print((\"The average protein lengh for the genes AT1 and AT5 is \"),  (sum(  (float(item['ProteinLength']) * 100) for item in protein  ) / len(protein)*100) / 10000 ) # Decimal sets number of digits...\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "rep = []\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('LocusGene.tsv') as csvfile:\n",
    "    protein_Reader = list(csv.DictReader(csvfile, delimiter=\"\\t\"))\n",
    "    print(\"The average protein lenght is\",  sum(  float(item['ProteinLength']) for item in protein_Reader  ) / len(protein_Reader) ) # can ask for the length of the list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writting reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalReport = (open(\"Totalreport.tsv\", \"w+\"))\n",
    "\n",
    "print(TotalReport.read())\n",
    "\n",
    "for line in TotalReport.readlines():\n",
    "\n",
    "\n",
    "print(TotalReport.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "</pre>\n",
    "## Don't forget to commit and push your answers before you leave!\n",
    "\n",
    "It was wonderful to have you in my class!  I hope to see you again soon!\n",
    "\n",
    "Good luck with your careers!!\n",
    "\n",
    "Mark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
